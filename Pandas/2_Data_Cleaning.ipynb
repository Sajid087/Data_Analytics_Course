{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e04f596",
   "metadata": {},
   "source": [
    "\n",
    "# Data Cleaning in Pandas\n",
    "\n",
    "## Introduction\n",
    "\n",
    "### What is Data Cleaning?\n",
    "Data cleaning is the process of preparing raw data for analysis by identifying and correcting errors, inconsistencies, and inaccuracies in the dataset. It ensures the data is reliable and ready for meaningful analysis.\n",
    "\n",
    "### Why is Data Cleaning Important?\n",
    "Poor data quality can lead to misleading insights and faulty decisions. Cleaning your data ensures:\n",
    "- Improved accuracy of analysis and predictions.\n",
    "- Reduced risk of errors during processing.\n",
    "- Better insights from your dataset.\n",
    "\n",
    "### Common Data Quality Issues\n",
    "Some common data quality issues include:\n",
    "- Missing values.\n",
    "- Duplicate entries.\n",
    "- Incorrect or inconsistent data types.\n",
    "- Outliers that can skew analysis.\n",
    "- Inconsistent formatting (e.g., capitalization, whitespace).\n",
    "\n",
    "### Why Pandas for Data Cleaning?\n",
    "Pandas is an ideal tool for data cleaning because it provides:\n",
    "- Intuitive syntax for handling missing data, duplicates, and more.\n",
    "- Tools for data type conversion and formatting.\n",
    "- Built-in methods to deal with outliers and inconsistencies.\n",
    "\n",
    "In this tutorial, we'll demonstrate key data cleaning techniques using Pandas with a real-world dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "920b21f8",
   "metadata": {},
   "source": [
    "\n",
    "## Loading the Dataset\n",
    "\n",
    "Let's load the `UberDataset.csv` to explore its structure and clean it step-by-step.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "424eb24e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>START_DATE</th>\n",
       "      <th>END_DATE</th>\n",
       "      <th>CATEGORY</th>\n",
       "      <th>START</th>\n",
       "      <th>STOP</th>\n",
       "      <th>MILES</th>\n",
       "      <th>PURPOSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01-01-2016 21:11</td>\n",
       "      <td>01-01-2016 21:17</td>\n",
       "      <td>Business</td>\n",
       "      <td>Fort Pierce</td>\n",
       "      <td>Fort Pierce</td>\n",
       "      <td>5.1</td>\n",
       "      <td>Meal/Entertain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01-02-2016 01:25</td>\n",
       "      <td>01-02-2016 01:37</td>\n",
       "      <td>Business</td>\n",
       "      <td>Fort Pierce</td>\n",
       "      <td>Fort Pierce</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01-02-2016 20:25</td>\n",
       "      <td>01-02-2016 20:38</td>\n",
       "      <td>Business</td>\n",
       "      <td>Fort Pierce</td>\n",
       "      <td>Fort Pierce</td>\n",
       "      <td>4.8</td>\n",
       "      <td>Errand/Supplies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01-05-2016 17:31</td>\n",
       "      <td>01-05-2016 17:45</td>\n",
       "      <td>Business</td>\n",
       "      <td>Fort Pierce</td>\n",
       "      <td>Fort Pierce</td>\n",
       "      <td>4.7</td>\n",
       "      <td>Meeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01-06-2016 14:42</td>\n",
       "      <td>01-06-2016 15:49</td>\n",
       "      <td>Business</td>\n",
       "      <td>Fort Pierce</td>\n",
       "      <td>West Palm Beach</td>\n",
       "      <td>63.7</td>\n",
       "      <td>Customer Visit</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         START_DATE          END_DATE  CATEGORY        START             STOP  \\\n",
       "0  01-01-2016 21:11  01-01-2016 21:17  Business  Fort Pierce      Fort Pierce   \n",
       "1  01-02-2016 01:25  01-02-2016 01:37  Business  Fort Pierce      Fort Pierce   \n",
       "2  01-02-2016 20:25  01-02-2016 20:38  Business  Fort Pierce      Fort Pierce   \n",
       "3  01-05-2016 17:31  01-05-2016 17:45  Business  Fort Pierce      Fort Pierce   \n",
       "4  01-06-2016 14:42  01-06-2016 15:49  Business  Fort Pierce  West Palm Beach   \n",
       "\n",
       "   MILES          PURPOSE  \n",
       "0    5.1   Meal/Entertain  \n",
       "1    5.0              NaN  \n",
       "2    4.8  Errand/Supplies  \n",
       "3    4.7          Meeting  \n",
       "4   63.7   Customer Visit  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Load the dataset\n",
    "import pandas as pd\n",
    "\n",
    "file_path = 'UberDataset.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first few rows\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4fe15f7",
   "metadata": {},
   "source": [
    "\n",
    "## Handling Missing Values\n",
    "\n",
    "### Why Handle Missing Values?\n",
    "Missing values can result from incomplete data collection or errors during data entry. Ignoring them can lead to biased results.\n",
    "\n",
    "### Techniques to Handle Missing Values\n",
    "1. **Drop missing values**: Remove rows or columns with missing data.\n",
    "2. **Impute missing values**: Fill in missing data with appropriate values (mean, median, mode, etc.).\n",
    "3. **Interpolation**: Estimate missing values using trends in the data.\n",
    "\n",
    "### Examples:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4a5027e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values per column:\n",
      "START_DATE      0\n",
      "END_DATE        1\n",
      "CATEGORY        1\n",
      "START           1\n",
      "STOP            1\n",
      "MILES           0\n",
      "PURPOSE       503\n",
      "dtype: int64\n",
      "\n",
      "After dropping rows with missing values:\n",
      "(653, 7)\n",
      "\n",
      "After filling missing values:\n",
      "   CATEGORY          PURPOSE\n",
      "0  Business   Meal/Entertain\n",
      "1  Business          Unknown\n",
      "2  Business  Errand/Supplies\n",
      "3  Business          Meeting\n",
      "4  Business   Customer Visit\n",
      "\n",
      "After interpolating missing values:\n",
      "0     5.1\n",
      "1     5.0\n",
      "2     4.8\n",
      "3     4.7\n",
      "4    63.7\n",
      "Name: MILES, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sajid\\AppData\\Local\\Temp\\ipykernel_19408\\1187824850.py:16: FutureWarning: DataFrame.interpolate with object dtype is deprecated and will raise in a future version. Call obj.infer_objects(copy=False) before interpolating instead.\n",
      "  df_interpolated = df.interpolate()\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Checking missing values\n",
    "print(\"Missing values per column:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Drop rows with missing values\n",
    "df_dropped = df.dropna()\n",
    "print(\"\\nAfter dropping rows with missing values:\")\n",
    "print(df_dropped.shape)\n",
    "\n",
    "# Fill missing values with a placeholder\n",
    "df_filled = df.fillna('Unknown')\n",
    "print(\"\\nAfter filling missing values:\")\n",
    "print(df_filled[['CATEGORY', 'PURPOSE']].head())\n",
    "\n",
    "# Interpolate numerical missing values\n",
    "df_interpolated = df.interpolate()\n",
    "print(\"\\nAfter interpolating missing values:\")\n",
    "print(df_interpolated['MILES'].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f69a80e9",
   "metadata": {},
   "source": [
    "\n",
    "## Removing Duplicates\n",
    "\n",
    "Duplicate entries can distort your analysis. Use `drop_duplicates()` to remove them.\n",
    "\n",
    "### Example:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73a2ffd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before removing duplicates: (1156, 7)\n",
      "After removing duplicates: (1155, 7)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Remove duplicate rows\n",
    "print(\"Before removing duplicates:\", df.shape)\n",
    "df_no_duplicates = df.drop_duplicates()\n",
    "print(\"After removing duplicates:\", df_no_duplicates.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37379a33",
   "metadata": {},
   "source": [
    "\n",
    "## Fixing Data Types\n",
    "\n",
    "Incorrect data types can cause errors during analysis. Use `astype()` or `to_numeric()` to convert data types.\n",
    "\n",
    "### Example:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "243940af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START_DATE    datetime64[ns]\n",
      "END_DATE              object\n",
      "CATEGORY              object\n",
      "START                 object\n",
      "STOP                  object\n",
      "MILES                float64\n",
      "PURPOSE               object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Convert START_DATE to datetime\n",
    "df['START_DATE'] = pd.to_datetime(df['START_DATE'], errors='coerce')\n",
    "\n",
    "# Convert MILES to numeric\n",
    "df['MILES'] = pd.to_numeric(df['MILES'], errors='coerce')\n",
    "\n",
    "# Display updated types\n",
    "print(df.dtypes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38dc7e81",
   "metadata": {},
   "source": [
    "\n",
    "## Handling Outliers\n",
    "\n",
    "Outliers can distort statistics and models. Use statistical methods to identify and handle them.\n",
    "\n",
    "### Example:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bdd316ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape before removing outliers: (1156, 7)\n",
      "Shape after removing outliers: (1078, 7)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Identify outliers using the interquartile range (IQR)\n",
    "Q1 = df['MILES'].quantile(0.25)\n",
    "Q3 = df['MILES'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Define bounds for outliers\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "# Filter out outliers\n",
    "df_no_outliers = df[(df['MILES'] >= lower_bound) & (df['MILES'] <= upper_bound)]\n",
    "print(\"Shape before removing outliers:\", df.shape)\n",
    "print(\"Shape after removing outliers:\", df_no_outliers.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd61c94c",
   "metadata": {},
   "source": [
    "\n",
    "## String Cleaning and Standardization\n",
    "\n",
    "Inconsistent string formatting can cause issues during analysis. Use methods like `strip()`, `lower()`, and `replace()` for standardization.\n",
    "\n",
    "### Example:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ebcdefa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   CATEGORY            PURPOSE\n",
      "0  business   Meal & Entertain\n",
      "1  business                NaN\n",
      "2  business  Errand & Supplies\n",
      "3  business            Meeting\n",
      "4  business     Customer Visit\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Standardize CATEGORY column\n",
    "df['CATEGORY'] = df['CATEGORY'].str.strip().str.lower()\n",
    "\n",
    "# Replace values in PURPOSE\n",
    "df['PURPOSE'] = df['PURPOSE'].str.replace('/', ' & ', regex=False)\n",
    "\n",
    "# Display cleaned columns\n",
    "print(df[['CATEGORY', 'PURPOSE']].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f2deb5d",
   "metadata": {},
   "source": [
    "\n",
    "## Date/Time Data Cleaning\n",
    "\n",
    "Date/time data is crucial for time series analysis. Use `to_datetime()` to ensure consistency.\n",
    "\n",
    "### Example:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a16b6ae4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           START_DATE            END_DATE    YEAR  MONTH\n",
      "0 2016-01-01 21:11:00 2016-01-01 21:17:00  2016.0    1.0\n",
      "1 2016-01-02 01:25:00 2016-01-02 01:37:00  2016.0    1.0\n",
      "2 2016-01-02 20:25:00 2016-01-02 20:38:00  2016.0    1.0\n",
      "3 2016-01-05 17:31:00 2016-01-05 17:45:00  2016.0    1.0\n",
      "4 2016-01-06 14:42:00 2016-01-06 15:49:00  2016.0    1.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Convert END_DATE to datetime\n",
    "df['END_DATE'] = pd.to_datetime(df['END_DATE'], errors='coerce')\n",
    "\n",
    "# Extract year and month\n",
    "df['YEAR'] = df['START_DATE'].dt.year\n",
    "df['MONTH'] = df['START_DATE'].dt.month\n",
    "\n",
    "# Display updated dataset\n",
    "print(df[['START_DATE', 'END_DATE', 'YEAR', 'MONTH']].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb71feae",
   "metadata": {},
   "source": [
    "\n",
    "## Conclusion\n",
    "\n",
    "In this tutorial, we covered:\n",
    "- Identifying and handling missing values.\n",
    "- Removing duplicates to avoid redundant data.\n",
    "- Fixing data types to ensure consistency.\n",
    "- Identifying and handling outliers.\n",
    "- Standardizing string data.\n",
    "- Cleaning and extracting insights from date/time data.\n",
    "\n",
    "### Best Practices for Maintaining Clean Data\n",
    "1. Regularly validate your data.\n",
    "2. Automate cleaning processes for repeatability.\n",
    "3. Document assumptions and cleaning steps.\n",
    "\n",
    "### Additional Resources\n",
    "- [Pandas Documentation](https://pandas.pydata.org/docs/)\n",
    "- Books on data cleaning and preparation.\n",
    "\n",
    "Clean data is the foundation of any successful analysis. Practice these techniques to improve your data workflows.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
